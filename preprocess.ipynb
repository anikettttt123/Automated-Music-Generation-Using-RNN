{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["pip install icecream"],"metadata":{"id":"-EnUq_Md0RLf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install import-ipynb\n"],"metadata":{"id":"wvdBV6ZZe7hG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import memory_saving_gradients"],"metadata":{"id":"8mAq2londlYe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import music21 as m21\n","import warnings\n","from icecream import ic\n","from tensorflow.keras.utils import to_categorical\n","import numpy as np\n","import json\n","from pprint import pprint"],"metadata":{"id":"Sl_OKLHwsspQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["warnings.filterwarnings(\"ignore\")"],"metadata":{"id":"JZPvwfCmuCS9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DATASET_PATH ='/content/drive/MyDrive/MelodyGeneration/sampleDataset'\n","PREPROCESSED_PATH ='/content/drive/MyDrive/MelodyGeneration/PPdataset'\n","SINGLE_FILE_DATASET_PATH ='/content/drive/MyDrive/MelodyGeneration/singleFileDataset'\n","NOTES_TO_INT_PATH ='/content/drive/MyDrive/MelodyGeneration/mappings/notes_to_int.json'\n","INT_TO_NOTES_PATH ='/content/drive/MyDrive/MelodyGeneration/mappings/int_to_notes.json'\n","ACCEPTABLE_DURATIONS = [0.25,0.5,0.75,1,2,3,4] #beats\n","SEQUENCE_LENGTH = 64"],"metadata":{"id":"Fo6hxIdjp-oC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# PREPROCESSING\n"],"metadata":{"id":"VPzfny9_74CR"}},{"cell_type":"code","source":["def load_dataset(dataset_path)->list:\n","  songs=[]\n","  songs_name=[]\n","  for paths,subdires,files in os.walk(dataset_path):\n","    for file in files:\n","      song = m21.converter.parse(os.path.join(dataset_path,file))\n","      songs.append(song)\n","      songs_name.append(file[:-4])\n","    return songs,songs_name"],"metadata":{"id":"yN_PSw9pp9V6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["songs,songs_name = load_dataset(DATASET_PATH)"],"metadata":{"id":"gkiMa7FJzc8K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def has_acceptable_duration(song,acceptable_durations) -> bool:\n","  for note in song.flatten().notesAndRests:\n","    if note.duration.quarterLength not in acceptable_durations:\n","      return False\n","    return True\n","\n"],"metadata":{"id":"vnXBedczKDno"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(len(songs)):\n","  ic(has_acceptable_duration(songs[i],ACCEPTABLE_DURATIONS))"],"metadata":{"id":"8YsD65R4z1QI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def transpose(song):\n","    #get the key of the song\n","    parts = song.getElementsByClass(m21.stream.Part) # there are 2 parts----->0 is right piano , 1 is left piano\n","    measure_part0= parts[0].getElementsByClass(m21.stream.Measure)\n","    key = measure_part0[0][4]\n","\n","    #estimate key using music21\n","    if not isinstance(key,m21.key.Key):\n","      key = song.analyze('key')\n","\n","    #getting the interval for transposition\n","    if key.mode == \"major\":\n","      interval = m21.interval.Interval(key.tonic, m21.pitch.Pitch('C'))\n","    elif key.mode==\"minor\":\n","      interval = m21.interval.Interval(key.tonic, m21.pitch.Pitch('A'))\n","\n","    #transposing song by calculated interval\n","    transposed_song = song.transpose(interval)\n","    return transposed_song"],"metadata":{"id":"F_sIAWoNhDT1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def encode_song(song,time_step = 0.25):\n","  encoded_song = []\n","  for event in song.flatten().notesAndRests:\n","    # handling rest\n","    if isinstance(event,m21.note.Rest):\n","        symbol = \"r\"\n","    #handling notes\n","\n","    elif isinstance(event,m21.note.Note):\n","      symbol = event.pitch.midi\n","\n","    else :\n","        symbol = event[0].pitch.midi #60\n","      #handling rests\n","\n","        #converting\n","    steps = int(event.duration.quarterLength/time_step)\n","\n","    for step in range(steps):\n","        if step==0:\n","          encoded_song.append(symbol)\n","        else:\n","          encoded_song.append(\"_\")\n","\n","  #casting encoded song to a list\n","  encoded_song_str =\" \".join(map(str,encoded_song))\n","  encoded_song_str.replace(\"r r\",\"r\")\n","\n","  return encoded_song_str\n"],"metadata":{"id":"ilCZYe0PhQdn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load(file_path):\n","  with open(file_path,\"r\") as fp:\n","    song = fp.read()\n","  return song"],"metadata":{"id":"50ZmLqelicp3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4XUUZHjvbqHV"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cJn0foe6Xhas"},"outputs":[],"source":["def preprocess(dataset_path):\n","\n","  # loading the dataset\n","  print(\"loading Songs.......\")\n","  songs,songs_name = load_dataset(dataset_path)\n","  print(f\"loaded {len(songs)} songs.\")\n","\n","  #filtering out songs on the basis of the duration\n","  print(\"Filtering Songs\")\n","\n","  for i,song in enumerate(songs):\n","    filtered_songs = len(songs_name)\n","\n","    if not has_acceptable_duration(song,ACCEPTABLE_DURATIONS):\n","\n","      continue\n","  # transposing song?!\n","    song = transpose(song)\n","    filtered_songs = filtered_songs-1\n","  # Encoding these songs with music time series representation eg [60,\"_\",\"_\",\"_\",62,\"_\",\"_\",\"_\",\"_\",62,\"_\",72,\"_\",70,\"_\",80,\"r\",........]\n","    encoded_song = encode_song(song)\n","\n","\n","  # saving the songs\n","    save_path = os.path.join(PREPROCESSED_PATH, str(songs_name[i]))\n","    with open(save_path, \"w\") as fp:\n","      fp.write(encoded_song)\n","\n","  print(f\"No. of songs filtered: {filtered_songs}/{len(songs_name)}\")\n","\n"]},{"cell_type":"code","source":["SEQUENCE_LENGTH = 64\n","def create_single_file_dataset(save_singleFileDataset_path,preprocessed_dataset,sequence_lenght):\n","\n","  new_song_delimiter = \"/ \"* sequence_lenght\n","  songs = \"\"\n","\n","  # loading encoded_song and add delimiters\n","  for path,_,files in os.walk(preprocessed_dataset):\n","    for file in files:\n","      file_path = os.path.join(preprocessed_dataset,file)\n","      song = load(file_path)\n","      songs = songs + song + \" \"+new_song_delimiter\n","      songs=songs[:]\n","\n","    # saving the datset\n","  with open(os.path.join(save_singleFileDataset_path,\"singleFileDataset.txt\"),\"w\") as fp:\n","    fp.write(songs)\n","\n","    return songs"],"metadata":{"id":"hJk3Wx_xwOOK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_mapping(songs):\n","  notes_to_int={}\n","  int_to_notes={}\n","  vocabulary = sorted(list(set(all_songs.split())))\n","  for i,symbol in enumerate(vocabulary):\n","    notes_to_int[symbol] = i\n","\n","  for symbol,i in notes_to_int.items():\n","    int_to_notes[i]=symbol\n","\n","  # saving vocab to a jason file\n","  with open(NOTES_TO_INT_PATH,\"w\") as fp:\n","    json.dump(notes_to_int,fp,indent=4)\n","  with open(INT_TO_NOTES_PATH,\"w\") as fp:\n","    json.dump(int_to_notes,fp,indent=4)\n","  return dict(notes_to_int),dict(int_to_notes)\n"],"metadata":{"id":"1Hi_tks7wTTM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def convert_songs_to_int(songs):\n","  converted_songs_dataset=[]\n","\n","  # # LOADING THE MAPPING JSON\n","  # with open(NOTES_TO_INT_PATH,\"r\") as fp:\n","  # notes_to_int = json.load(fp)\n","  songs = songs.split()\n","  for event in songs:\n","    converted_songs_dataset.append(notes_to_int[event])\n","\n","  return converted_songs_dataset"],"metadata":{"id":"kULU8I2fMr0G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preprocess(DATASET_PATH)"],"metadata":{"id":"g8wuW2TDKM5a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# merging all our dataset into a single file\n","all_songs=create_single_file_dataset(SINGLE_FILE_DATASET_PATH,PREPROCESSED_PATH,SEQUENCE_LENGTH)\n","print(all_songs)\n"],"metadata":{"id":"aQMFrunnkb_e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#mapping our notes\n","notes_to_int,int_to_notes = create_mapping(all_songs)\n","num_unique_notes = len(notes_to_int)\n","print(notes_to_int.items())"],"metadata":{"id":"t-qb8UVMf1AA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training Phase"],"metadata":{"id":"r37o7nksLewZ"}},{"cell_type":"code","source":["import tensorflow.keras as keras\n","from tensorflow.keras.layers import LSTM,GRU,Dense,Dropout,Input,BatchNormalization, Attention\n","from tensorflow.keras.models import Sequential,load_model\n","from tensorflow.keras.optimizers import Adam\n","from matplotlib import pyplot as plt\n","\n","MODEL_PATH = '/content/drive/MyDrive/MelodyGeneration/Models'"],"metadata":{"id":"LBQOdALdMLGz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generating_training_sequences(sequence_length):\n","\n","  songs = load(os.path.join(SINGLE_FILE_DATASET_PATH,\"singleFileDataset.txt\"))\n","  int_songs = convert_songs_to_int(songs)\n","  unique_events = len(set(int_songs))\n","\n","  inputs,targets=[],[]\n","\n","  num_sequences = len(int_songs)-sequence_length\n","\n","  for i in range(num_sequences):\n","    inputs.append(int_songs[i:i+sequence_length])  #input_dim-> num_sequences * sequence_length\n","    targets.append(int_songs[i+sequence_length])   #targets_dim-> num_sequences\n","\n","  inputs= to_categorical(inputs,num_classes=unique_events)\n","  targets = np.array(targets)\n","\n","  print(f\"There are {len(inputs)} sequences.\")\n","  return inputs,targets"],"metadata":{"id":"7UuZJGkZPZyQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Using dropout inside the function parameter or outside?\n","\n","You can use a Dropout(...) layer, it's not \"wrong\", but it will possibly drop \"timesteps\" too! (Unless you set noise_shape properly or use SpatialDropout1D, which is currently not documented yet)\n","\n","Maybe you want it, maybe you dont. If you use the parameters in the recurrent layer, you will be applying dropouts only to the other dimensions, without dropping a single step. This seems healthy for recurrent layers, unless you want your network to learn how to deal with sequences containing gaps (this last sentence is a supposal).\n","\n","Also, with the dropout parameters, you will be really dropping parts of the kernel as the operations are dropped \"in every step\", while using a separate layer will let your RNN perform non-dropped operations internally, since your dropout will affect only the final output."],"metadata":{"id":"wOROxNdqQvAG"}},{"cell_type":"code","source":["from keras.layers import Layer\n","import keras.backend as K"],"metadata":{"id":"IjPpKh7oWPZK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class attention(Layer):\n","    def __init__(self,**kwargs):\n","        super(attention,self).__init__(**kwargs)\n","\n","    def build(self,input_shape):\n","        self.W=self.add_weight(name='attention_weight', shape=(input_shape[-1],1),\n","                               initializer='random_normal', trainable=True)\n","        self.b=self.add_weight(name='attention_bias', shape=(input_shape[1],1),\n","                               initializer='zeros', trainable=True)\n","        super(attention, self).build(input_shape)\n","\n","    def call(self,x):\n","        # Alignment scores. Pass them through tanh function\n","        e = K.tanh(K.dot(x,self.W)+self.b)\n","        # Remove dimension of size 1\n","        e = K.squeeze(e, axis=-1)\n","        # Compute the weights\n","        alpha = K.softmax(e)\n","        # Reshape to tensorFlow format\n","        alpha = K.expand_dims(alpha, axis=-1)\n","        # Compute the context vector\n","        context = x * alpha\n","        context = K.sum(context, axis=1)\n","        return context"],"metadata":{"id":"qbfH0GWqWJJF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_model(units,output_size,model_type):\n","  match model_type:\n","    case \"1lstm\":\n","        input = Input(shape = (None,output_size),name = \"INPUT_LAYER\")\n","        lstm = LSTM(units=units , name = \"LSTM_LAYER\")(input)\n","        dropout = Dropout(0.2)(lstm)\n","        output = Dense(output_size,activation = \"softmax\", name=\"OUTPUT_LAYER\")(dropout)\n","        model = keras.Model(input,output)\n","    case \"2lstm_doubleD\":\n","        input = Input(shape = (None,output_size),name = \"INPUT_LAYER\")\n","        lstm_1 = LSTM(units=units ,return_sequences= True, name = \"LSTM_LAYER_1\", dropout=0.2)(input)\n","        lstm_2 = LSTM(units=units , name = \"LSTM_LAYER_2\",dropout = 0.2)(lstm_1)\n","\n","        output = Dense(output_size,activation = \"softmax\", name=\"OUTPUT_LAYER\")(lstm_2)\n","        model = keras.Model(input,output)\n","    case \"2gru\" :\n","        input = Input(shape = (None,output_size),name = \"INPUT_LAYER\")\n","        gru_1 = GRU(units=units ,return_sequences= True, name = \"GRU_LAYER_1\")(input)\n","        gru_2 = GRU(units=units , name = \"GRU_LAYER_2\")(gru_1)\n","        dropout = Dropout(0.3)(gru_2)\n","        output = Dense(output_size,activation = \"softmax\", name=\"OUTPUT_LAYER\")(dropout)\n","        model = keras.Model(input,output)\n","\n","    case \"mixed_model\" :\n","      input = Input(shape = (None,output_size),name = \"INPUT_LAYER\")\n","      gru_1 = LSTM(units=units ,return_sequences= True, name = \"GRU_LAYER_1\")(input)\n","\n","      lstm_2 = GRU(units=units , name = \"LSTM_LAYER_2\")(gru_1)\n","      dropout = Dropout(0.2)(lstm_2)\n","\n","\n","      output = Dense(output_size,activation = \"softmax\", name=\"OUTPUT_LAYER\")(dropout)\n","      model = keras.Model(input,output)\n","\n","    case \"attentionGDL\" :\n","\n","        input = Input(shape = (None,output_size),name = \"INPUT_LAYER\")\n","\n","        layer_1 = GRU(units=units ,return_sequences= True, name = \"LSTM_LAYER_1\")(input)\n","        layer_2 = Dropout(0.3)(layer_1)\n","        layer_3 =LSTM(units=units , name = \"LSTM_LAYER_2\")(layer_2)\n","\n","        layer_4= Attention()([layer_3, layer_3])\n","\n","        layer_5 = BatchNormalization()(layer_4)\n","\n","        output = Dense(output_size,activation = \"softmax\", name=\"OUTPUT_LAYER\")(layer_5)\n","        model = keras.Model(input,output)\n","\n","\n","\n","\n","\n","\n","\n","  model.compile(loss = \"sparse_categorical_crossentropy\",\n","                optimizer = Adam(learning_rate=0.001),\n","                metrics = [\"accuracy\"])\n","  model.summary()\n","\n","  return model\n"],"metadata":{"id":"w1tzvkE7Lkcj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load(file_path):\n","  with open(file_path,\"r\") as fp:\n","    song = fp.read()\n","  return song"],"metadata":{"id":"lrJHiwrxMUqN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_songs = load(os.path.join(SINGLE_FILE_DATASET_PATH,\"singleFileDataset.txt\"))"],"metadata":{"id":"lFuMpZ-mLo0N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["notes_to_int,int_to_notes = create_mapping(all_songs)\n","num_unique_notes = len(notes_to_int)\n","print(notes_to_int.items())"],"metadata":{"id":"WfHcwZUO7xv3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["UNITS = 256\n","OUTPUT_SIZE = num_unique_notes = len(list(set(all_songs.split())))\n","EPOCHS = 50\n","BATCH_SIZE = 64\n"],"metadata":{"id":"xtjbs7dbKrfL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = generate_model(units = UNITS, output_size=OUTPUT_SIZE,model_type='attentionGDL')"],"metadata":{"id":"4UDij31dYDmP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["del model"],"metadata":{"id":"KJyy9fbeafIw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_model(epochs,batch_size,model_type):\n","# def train_model(x_train,y_train,epochs,batch_size,model_type):\n","\n","  inputs,targets = generating_training_sequences(SEQUENCE_LENGTH)\n","  # ic(np.shape(inputs),np.shape(targets))\n","\n","  model = generate_model(units=256, output_size = num_unique_notes,model_type= model_type)\n","\n","  # model.fit(x_train,y_train,epochs = epochs , batch_size = batch_size)\n","  history=model.fit(inputs,targets,epochs = epochs , batch_size = batch_size)\n","  plt.plot(history.history['accuracy'])\n","  plt.plot(history.history['loss'])\n","  plt.show()\n","\n","  model.save(os.path.join(MODEL_PATH,model_type+\".h5\"))"],"metadata":{"id":"CeSXFliYMMNs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Shapes (None,) and (None, 64, 75) are incompatible"],"metadata":{"id":"0Awya8-BavZS"}},{"cell_type":"code","source":["inputs,targets = generating_training_sequences(SEQUENCE_LENGTH)"],"metadata":{"id":"b5qeXbzKCmhm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["del inputs,targets"],"metadata":{"id":"Qeg7VeoFDmfM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_model(epochs = 64,batch_size = 64, model_type = \"attentionGDL\")"],"metadata":{"id":"_b68H3CDXA_L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Generating Melody"],"metadata":{"id":"IPZz10tHCPzA"}},{"cell_type":"code","source":["from matplotlib import pyplot as plt"],"metadata":{"id":"IK4hWXwenHsI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(model.history['accuracy'])"],"metadata":{"id":"MukWtVv1mtnE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json"],"metadata":{"id":"Ce6Vjdp-MMH1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = load_model(os.path.join(MODEL_PATH,\"2lstm.h5\"))"],"metadata":{"id":"WqLm8epBOwFK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(NOTES_TO_INT_PATH,\"r\") as fp:\n","  notes_to_int = json.load(fp)\n","\n","with open(INT_TO_NOTES_PATH,\"r\") as fp:\n","  int_to_notes = json.load(fp)"],"metadata":{"id":"H01sqCAfMGYA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"W2WTWwnXpOoS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"W4x0f0puCPIn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_medlody(model,seed_sequence,start_symbol,num_steps,max_sequence_length,temperature):\n","  '''num_steps: No. of the steps in time series representation we want our generator to output,\n","  max_sequence_lenght : how many steps we want to consider in the seed for the network to be passed as the input(in our case its  64)'''\n","  def sample_with_temperature(probies, temp):\n","\n","    prediction = np.log(probies)/ temp\n","    probies = np.exp(prediction)/np.sum(np.exp(prediction))\n","    choices = range(len(probies))\n","    return np.random.choice(choices,p = probies)\n","\n","\n","\n","  with open(NOTES_TO_INT_PATH,\"r\") as fp:\n","    notes_to_int = json.load(fp)\n","\n","  with open(INT_TO_NOTES_PATH,\"r\") as fp:\n","    int_to_notes = json.load(fp)\n","\n","  seed_sequence = seed_sequence.split()\n","  melody = start_symbol + seed_sequence\n","\n","\n","  seed_sequence = [notes_to_int[symbol] for symbol in seed_sequence]\n","\n","  for _ in range(num_steps):\n","\n","    #taking all the last 64 steps as seed will be growing for num_steps steps\n","    seed_sequence = seed_sequence[-max_sequence_length:]\n","\n","\n","    #converting into one hot encoding as our model is trained using these\n","    onehot_seed = to_categorical(seed_sequence, num_classes = len(int_to_notes))\n","\n","    #we need to add another dimension because predict() expects 3 dimensions as one dimension tells the batch size\n","    # in our case the batch size is 1 as we our passing just one sequence for prediction\n","    onehot_seed = np.reshape(onehot_seed,(1,len(seed_sequence),len(int_to_notes)))\n","    # onehot_seed = onehot_seed[np.newaxis(),...]\n","    # onehot_seed = np.expand_dims(onehot_seed, (1,len(seed_sequence),len(int_to_notes)))\n","\n","    #making prediction     0.48 0.44 /0.7\n","    #now since we have batch size of 1,hence prediction will return list of lenght 1\n","    probabilities = model.predict(onehot_seed)[0] #[0.2,0.5,0.1,...] size = no. of unique notes  4-----[ [] ]\n","    #now we can return the index with the highest probability , but its a rigit choice\n","    #thus we gonna use temperature to bring these probability values closer aka scaling the distribution\n","    # temp->inf. ----- all the different values tend to have same value\n","    # tem->0 ------ all the values become deterministic highest value become 1 low 0\n","    # temp-> 1 ------ does nothing to the orignal distribution\n","    # intuition ==> value is directly proportional to predictibility of the sampling\n","    #  0 - deterministic inf. - random\n","\n","\n","    output_int = sample_with_temperature(probabilities,temperature)\n","\n","    seed_sequence.append(output_int)\n","\n","    # now we need to check if the output_int is \"/\"\n","    output_symbol = int_to_notes[str(output_int)]\n","    if output_symbol == \"/\":\n","      break\n","    melody.append(output_symbol)\n","\n","\n","\n","\n","\n","\n","\n","\n","  return melody\n"],"metadata":{"id":"a4C3t6Y4muEe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def MelodyGenerator(model_path,model_type ,sequence_length,seed ):\n","  model = load_model(os.path.join(model_path,model_type))\n","\n","\n","  start_symbol = [\"/\"]* sequence_length\n","\n","  melody=generate_medlody(model,seed_sequence=seed,\n","                    start_symbol=start_symbol,\n","                    num_steps=500,\n","                    max_sequence_length=sequence_length,\n","                    temperature=0.7)\n","\n","  return melody\n","\n","\n"],"metadata":{"id":"95BsqG9kMFo7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seed = 'r _ _ _ _ _ _ _ _ _ _ _ 48 _ 48 _ 48 _ 48 _ 48 _ 48 _ 64 48 _ 65 48 _ 62 64 48 _ 65 66 _ _ _ _ _ 48 _ 48 _ 48 _ 67 _ _ _ _ _ _ 48 _ 48 _ 48 _ 48 _ 69 r 48 _ 66 67 48 _ 68 68 _ _' #string valu\n","print(dict(enumerate(seed.split())))\n"],"metadata":{"id":"EBeNaIgAt2se","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700248888451,"user_tz":-330,"elapsed":4,"user":{"displayName":"Piyush Nankani","userId":"04316022507233046962"}},"outputId":"65e40ae3-a9cb-4fe0-c16b-d732782db883"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{0: 'r', 1: '_', 2: '_', 3: '_', 4: '_', 5: '_', 6: '_', 7: '_', 8: '_', 9: '_', 10: '_', 11: '_', 12: '48', 13: '_', 14: '48', 15: '_', 16: '48', 17: '_', 18: '48', 19: '_', 20: '48', 21: '_', 22: '48', 23: '_', 24: '64', 25: '48', 26: '_', 27: '65', 28: '48', 29: '_', 30: '62', 31: '64', 32: '48', 33: '_', 34: '65', 35: '66', 36: '_', 37: '_', 38: '_', 39: '_', 40: '_', 41: '48', 42: '_', 43: '48', 44: '_', 45: '48', 46: '_', 47: '67', 48: '_', 49: '_', 50: '_', 51: '_', 52: '_', 53: '_', 54: '48', 55: '_', 56: '48', 57: '_', 58: '48', 59: '_', 60: '48', 61: '_', 62: '69', 63: 'r', 64: '48', 65: '_', 66: '66', 67: '67', 68: '48', 69: '_', 70: '68', 71: '68', 72: '_', 73: '_'}\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"YwFElVjXDdiS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = MelodyGenerator(MODEL_PATH,'2lstm.h5',SEQUENCE_LENGTH,seed)"],"metadata":{"id":"HLtW4iNsL7xU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X)"],"metadata":{"id":"oNl9rGfnwv1c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# CONVERTING SEQUENCE INTO MIDI FILE"],"metadata":{"id":"PrjeL9xHuaMH"}},{"cell_type":"code","source":["X[67:]"],"metadata":{"id":"PWottYqQPGwu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["m21_event = m21.note.Note(int('52'),quarterLength = 0.25)\n","m21_event"],"metadata":{"id":"dZzZ1J6jPco5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_melody(melody,step_duration = 0.25,format = \"midi\",savefile_path = \"music.mid\"):\n","# step_duration: \"the amount of duration in a quater length\n","# that we have at each time step in our reperesentation\"\n","\n","# creating music21 Stream\n","# we would not be pushing time signature, parts or measures in our stream object\n","# keeping the things at default set by music21 , ps- ts is 4/4\n","\n","  stream = m21.stream.Stream()\n","\n","\n","  #parsing and create note/rest\n","  #  60 _ _ _ r _ 55\n","  start_symbol= None #\n","  step_counter = 1 #its gona keep track of all the steps we have for a event\n","  #if a step counter is 4 than it would be called a quater lenght note, ie 1 beat duration ie a quarter_note\n","\n","  for i,symbol in enumerate(melody[64:]):\n","    ic(i,symbol,start_symbol)\n","    #case of notes/rest\n","    if symbol !=\"_\" or i+1 == len(melody[64:]):\n","      #but before dealing we want to ensure we are dealing with note/rest after the first one\n","      if start_symbol is not None:\n","\n","        quarter_length_duration = step_duration*step_counter\n","        # ic(start_symbol)\n","        # ic(symbol)\n","        #handling rest\n","        if start_symbol=='r':\n","          m21_event = m21.note.Rest(length=quarter_length_duration)\n","\n","        else:\n","          m21_event = m21.note.Note(int(start_symbol),quarterLength = quarter_length_duration) #number expressing the midi note corresponding to its pitch too\n","\n","        stream.append(m21_event)\n","        step_counter = 1\n","\n","\n","      start_symbol = symbol\n","    else:\n","      step_counter +=1\n","\n","  stream.write(format,savefile_path)\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"c6uAUK9Cumn7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X[64:85])"],"metadata":{"id":"zZ6KiFKuR2Ew"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X[64:][10:15])"],"metadata":{"id":"Z0C-T_dgRmii"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_melody(X,savefile_path='/content/drive/MyDrive/MelodyGeneration/melodyyyy.mid')"],"metadata":{"id":"UAyg6z7fNcW9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# SCRIPTING SPACE FOR CODE TESTING"],"metadata":{"id":"FEJ0eaGBR4F3"}},{"cell_type":"code","source":["print(len(X)-64-24)"],"metadata":{"id":"r4qBQQZltSxI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","songs=[]\n","songs_name=[]\n","dataset_path = '/content/drive/MyDrive/MelodyGeneration/dataset/'\n","for paths,subdires,files in os.walk(dataset_path):\n","  for file in files[:5]:\n","    song = m21.converter.parse(os.path.join(dataset_path,file))\n","    songs.append(song)\n","    songs_name.append(file)"],"metadata":{"id":"oIWl9KUDQPDl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_song = songs[0]\n","print(\"has acceptable duration?\", has_acceptable_duration(test_song,ACCEPTABLE_DURATIONS))"],"metadata":{"id":"54oiRY-eR-Vz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["parts = test_song.getElementsByClass(m21.stream.Part) # there are 2 parts----->0 is right piano , 1 is left piano\n","measure_part0= parts[0].getElementsByClass(m21.stream.Measure)\n","key = measure_part0[0][4]\n","# measure_part contains total number of measure in a music_piece\n","# for this test case we have 388 measure, offset is 3 (no. of beats in a bar) ie 3/4 time signature\n","print(f\"No. of parts in this song are: {len(parts[:])}\")\n","print(\"Key of the music measure is:\",key)\n","print(\"predicted key after analyzing:\" ,test_song.analyze('key'))"],"metadata":{"id":"j39TZgAdWTms"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BBfO352-tNOr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!yes | add-apt-repository ppa:mscore-ubuntu/mscore3-stable\n","!apt install musescore3"],"metadata":{"id":"t5OtZ8vatuLw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tsong= transpose(test_song)\n","\n","# tsong.show()"],"metadata":{"id":"Y9TpYudjtZZO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoded_song = encode_song(tsong)\n","print(encoded_song)\n"],"metadata":{"id":"MkB5EJ6hljvD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pprint import pprint\n","encoded_song = encode_song(tsong,0.5)\n","# pprint(encoded_song)\n","encoded_song.replace(\"r r\", \"r\")\n","# print(next(tsong.flat.notesAndRests[0].event.pitch.midi))\n"],"metadata":{"id":"nLcVZcfDy9Ic"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# chord1 = m21.chord.Chord(['C4', 'E4', 'G4'])\n","# print(chord1.duration.quarterLength/0.25)"],"metadata":{"id":"DzIhzRfEEPQp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7NNLxEH_Kuf2"},"execution_count":null,"outputs":[]}]}